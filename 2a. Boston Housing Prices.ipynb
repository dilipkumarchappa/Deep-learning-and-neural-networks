{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2a. Boston Housing Prices_Eager_Execution.ipynb","provenance":[],"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"X_cdgs6Gtnsc","colab_type":"text"},"source":["#### Load TensorFlow"]},{"cell_type":"code","metadata":{"id":"phluL_KyGgwc","colab_type":"code","colab":{}},"source":["#Make sure tf 2.x is installed\n","!pip install -U tensorflow --quiet"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5b_EywEw4MMe","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","tf.__version__"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"21W7saMGt1_F","colab_type":"text"},"source":["#### Load Data"]},{"cell_type":"code","metadata":{"id":"2F_QcYwH4u7I","colab_type":"code","colab":{}},"source":["#Load Boston Housing dataset available within tensorflow\n","(train_x, train_y),(_,_) = tf.keras.datasets.boston_housing.load_data(test_split=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Aq0UwZU0iZhV","colab_type":"code","colab":{}},"source":["#Check how many training examples we have\n","train_x.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_GauIClD233O","colab_type":"code","colab":{}},"source":["type(train_x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oY-bDhDSid0f","colab_type":"code","colab":{}},"source":["#Labels for our examples\n","train_y.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mOd3HiMFLX9j","colab_type":"code","colab":{}},"source":["train_x.dtype"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lADXNbMKGH_g","colab":{}},"source":["train_x = train_x.astype('float32')\n","train_y = train_y.astype('float32')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TKDsS4vKGl3E","colab_type":"code","colab":{}},"source":["train_x.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FXk9VbBz_Mbh","colab_type":"code","colab":{}},"source":["train_y.shape"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fOIoE3qCt9Wp","colab_type":"text"},"source":["#### Build Model"]},{"cell_type":"markdown","metadata":{"id":"uSMg5HDluCZG","colab_type":"text"},"source":["Define Weights and Bias"]},{"cell_type":"code","metadata":{"id":"1qHkc0mS_KZP","colab_type":"code","colab":{}},"source":["#We are initializing weights and Bias with Zero\n","w = tf.zeros(shape=(13,1))\n","b = tf.zeros(shape=(1))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MP8U92hduNeV","colab_type":"text"},"source":["Define a function to calculate prediction"]},{"cell_type":"code","metadata":{"id":"ARk9SVAb_jBA","colab_type":"code","colab":{}},"source":["def prediction(x, w, b):\n","    \n","    xw_matmul = tf.matmul(x, w)\n","    y = tf.add(xw_matmul, b)\n","    \n","    return y"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0QKcoDtbuhDl","colab_type":"text"},"source":["Function to calculate Loss (Mean Squared Error)"]},{"cell_type":"code","metadata":{"id":"zEkRNWEa_q45","colab_type":"code","colab":{}},"source":["def loss(y_actual, y_predicted):\n","    \n","    diff = y_actual - y_predicted\n","    sqr = tf.square(diff)\n","    avg = tf.reduce_mean(sqr)\n","    \n","    return avg"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2U2j7okPul9V","colab_type":"text"},"source":["Function to train the Model\n","\n","1.   Record all the mathematical steps to calculate Loss. We will record the steps using GradientTape\n","2.   Calculate Gradients of Loss w.r.t weights and bias\n","3.   Update Weights and Bias based on gradients and learning rate\n","\n"]},{"cell_type":"code","metadata":{"id":"r_Zu3u8IARZu","colab_type":"code","colab":{}},"source":["def train(x, y_actual, w, b, learning_rate=0.01):\n","    \n","    #Record mathematical operations on 'tape' to calculate loss\n","    with tf.GradientTape() as t:\n","        \n","        t.watch([w,b])\n","        \n","        current_prediction = prediction(x, w, b)\n","        current_loss = loss(y_actual, current_prediction)\n","    \n","    #Calculate Gradients for Loss with respect to Weights and Bias\n","    dw, db = t.gradient(current_loss,[w, b])\n","    \n","    #Update Weights and Bias\n","    w = w - learning_rate*dw\n","    b = b - learning_rate*db\n","    \n","    return w, b"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zcXDZ6N5vNw-","colab_type":"text"},"source":["#### Start Training"]},{"cell_type":"code","metadata":{"id":"gOY134RfEpbq","colab_type":"code","colab":{}},"source":["#Train for 100 Steps\n","for i in range(100):\n","    \n","    w, b = train(train_x, train_y, w, b, learning_rate=0.01)\n","    print('Current Loss on iteration', i, \n","          loss(train_y, prediction(train_x, w, b)).numpy())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DDcxSozRxyer","colab_type":"code","colab":{}},"source":["#Check Weights and Bias\n","print('Weights:\\n', w.numpy())\n","print('Bias:\\n',b.numpy())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Feh6mpAXlUd9","colab_type":"code","colab":{}},"source":["train_x[0]"],"execution_count":0,"outputs":[]}]}